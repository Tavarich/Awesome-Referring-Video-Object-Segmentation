# Awesome-Referring-Video-Object-Segmentation[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

Continually updating papers of referring video object segmentationðŸ˜Š

\* refers to no official method nameðŸ«¡ 

Other awesome projects: [Awesome-Video-Instance-Segmentation](https://github.com/fanghaook/Awesome-Video-Instance-Segmentation)

## 2024

| Model    | Title                                                        | Venue | Paper                                                        | Code                                          |
| -------- | :----------------------------------------------------------- | :---- | :----------------------------------------------------------- | --------------------------------------------- |
| LoSh | LoSh: Long-Short Text Joint Prediction Network for Referring Video Object Segmentation | CVPR | [PDF](https://arxiv.org/pdf/2306.08736.pdf) |  |
| DSHMP* | Decoupling Static and Hierarchical Motion Perception for Referring Video Segmentation | CVPR |  |  |
| TCE-RVOS | Temporal Context Enhanced Referring Video Object Segmentation | WACV  | [PDF](https://openaccess.thecvf.com/content/WACV2024/papers/Hu_Temporal_Context_Enhanced_Referring_Video_Object_Segmentation_WACV_2024_paper.pdf) | [Code](https://github.com/haliphinx/TCE-RVOS) |
| MUTR     | Referred by Multi-Modality: A Unified Temporal Transformer for Video Object Segmentation | AAAI  | [PDF](https://arxiv.org/pdf/2305.16318.pdf)                  | [Code](https://github.com/OpenGVLab/MUTR)     |
| FTEA     | Fully Transformer-Equipped Architecture for end-to-end Referring Video Object Segmentation | IP&M  | [PDF](https://www.sciencedirect.com/science/article/pii/S0306457323003035) |                                               |
| TrackGPT | Tracking with Human-Intent Reasoning | Arxiv  | [PDF](https://arxiv.org/abs/2312.17448) | [Code](https://github.com/jiawen-zhu/TrackGPT)|
| UniVS    | UniVS: Unified and Universal Video Segmentation with Prompts as Queries  | Arxiv | [PDF](https://arxiv.org/pdf/2402.18115.pdf)| [Code](https://github.com/MinghanLi/UniVS) |
| LTCA    | LTCA: Long-range Temporal Context Attention for Referring Video Object Segmentation  | Arxiv | [PDF]()| [Code](https://github.com/cilinyan/LTCA) |
| VD-IT   | Exploring Pre-trained Text-to-Video Diffusion Models for Referring Video Object Segmentation  | Arxiv | [PDF](https://arxiv.org/pdf/2403.12042.pdf)| [Code](https://github.com/buxiangzhiren/VD-IT) |
| HTR   | Towards Temporally Consistent Referring Video Object Segmentation  | Arxiv | [PDF](https://arxiv.org/pdf/2403.19407.pdf)|  |

## 2023

| Model       | Title                                                        | Venue   | Paper                                                        | Code                                                         |
| :---------- | :----------------------------------------------------------- | :------ | :----------------------------------------------------------- | ------------------------------------------------------------ |
| OnlineRefer | OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf) | [Code](https://github.com/wudongming97/OnlineRefer)          |
| LMPM        | MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.pdf) | [Code](https://github.com/henghuiding/MeViS)                 |
| SgMg        | Spectrum-guided Multi-granularity Referring Video Object Segmentation | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf) | [Code](https://github.com/bo-miao/SgMg)                      |
| TempCD      | Temporal Collection and Distribution for Referring Video Object Segmentation | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf) | [Project](https://toneyaya.github.io/tempcd/)                |
| HTML        | HTML: Hybrid Temporal-scale Multimodal Learning Framework for Referring Video Object Segmentation | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.pdf) | [Project](https://mingfei.info/HTML/)                        |
| R2VOS       | Robust Referring Video Object Segmentation with Cyclic Structural Consensus | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.pdf) | [Code](https://github.com/lxa9867/R2VOS)                     |
| FS-RVOS     | Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.pdf) | [Code](https://github.com/hengliusky/Few_shot_RVOS)          |
| UniRef      | Segment Every Reference Object in Spatial and Temporal Spaces | ICCV    | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.pdf) | [Code](https://github.com/FoundationVision/UniRef)           |
| SOC         | SOC: Semantic-Assisted Object Cluster for Referring Video Object Segmentation | NeurlPS | [PDF](https://arxiv.org/pdf/2305.17011.pdf)                  | [Code](https://github.com/RobertLuo1/NeurIPS2023_SOC)        |
| DMFormer    | Decoupling Multimodal Transformers for Referring Video Object Segmentation | TCSVT   | [PDF](https://ieeexplore.ieee.org/document/10147907)         | [Code](https://github.com/gaomingqi/dmformer)                |
| UniMM*      | Unified Multi-Modality Video Object Segmentation Using Reinforcement Learning | TCSVT   | [PDF](https://ieeexplore.ieee.org/abstract/document/10146303) |                                                              |
| Locater     | Local-Global Context Aware Transformer for Language-Guided Video Segmentation | TPAMI   | [PDF](https://ieeexplore.ieee.org/abstract/document/10083244) | [Code](https://github.com/leonnnop/Locater)                  |
| VLT         | VLT: Vision-Language Transformer and Query Generation for Referring Segmentation | TPAMI   | [PDF](https://ieeexplore.ieee.org/abstract/document/9932025) | [Code](https://github.com/henghuiding/Vision-Language-Transformer) |
| LASTC*      | Language-Aware Spatial-Temporal Collaboration for Referring Video Segmentation | TPAMI   | [PDF](https://ieeexplore.ieee.org/document/10013778)         |                                                              |
| CLUE        | CLUE: Contrastive language-guided learning for referring video object segmentation | PRL     | [PDF](https://www.sciencedirect.com/science/article/abs/pii/S0167865523003641) |                                                              |
| BIFIT       | Bidirectional Correlation-Driven Inter-Frame Interaction Transformer for Referring Video Object Segmentation | Arxiv   | [PDF](https://arxiv.org/pdf/2307.00536.pdf)                  |                                                              |
| EPCFormer   | EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation | Arxiv   | [PDF](https://arxiv.org/pdf/2308.04162.pdf)                  | [Code](https://github.com/lab206/EPCFormer)                  |
| RefSAM      | Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation | Arxiv   | [PDF](https://arxiv.org/pdf/2307.00997.pdf)                  | [Code](https://github.com/LancasterLi/RefSAM)                |
| UniRef++    | UniRef++: Segment Every Reference Object in Spatial and Temporal Spaces | Arxiv   | [PDF](https://arxiv.org/abs/2312.15715)                      | [Code](https://github.com/FoundationVision/UniRef)           |
| SimRVOS     | Learning Referring Video Object Segmentation from Weak Annotation | Arxiv   | [PDF](https://arxiv.org/pdf/2308.02162.pdf)                  |                                                              |

## 2022

| Model       | Title                                                        | Venue  | Paper                                                        | Code                                            |
| :---------- | :----------------------------------------------------------- | :----- | :----------------------------------------------------------- | :---------------------------------------------- |
| MTTR        | End-to-End Referring Video Object Segmentation with Multimodal Transformers | CVPR   | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Botach_End-to-End_Referring_Video_Object_Segmentation_With_Multimodal_Transformers_CVPR_2022_paper.pdf) | [Code]()                                        |
| ReferFormer | Language as Queries for Referring Video Object Segmentation  | CVPR   | [PDF](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Language_As_Queries_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.html) | [Code]()                                        |
| LBDT        | Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation | CVPR   | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Language-Bridged_Spatial-Temporal_Interaction_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.pdf) | [Code]()                                        |
| MLRL*       | Multi-Level Representation Learning with Semantic Alignment for Referring Video Object Segmentation | CVPR   | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Multi-Level_Representation_Learning_With_Semantic_Alignment_for_Referring_Video_Object_CVPR_2022_paper.pdf) |                                                 |
| MANet       | Multi-Attention Network for Compressed Video Referring Object Segmentation | ACM MM | [PDF](https://dl.acm.org/doi/pdf/10.1145/3503161.3547761)    | [Code](https://github.com/DexiangHong/MANet)    |
| YOFO        | You Only Infer Once: Cross-Modal Meta-Transfer for Referring Video Object Segmentation | AAAI   | [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/20017) |                                                 |
| OATNet      | Object-Agnostic Transformers for Video Referring Segmentation | TIP    | [PDF](https://ieeexplore.ieee.org/abstract/document/9744457) |                                                 |
| EFCMA*      | Referring Segmentation via Encoder-Fused Cross-Modal Attention Network | TPAMI  | [PDF](https://ieeexplore.ieee.org/document/9946403)          |                                                 |
| RefVOS      | A Closer Look at Referring Expressions for Video Object Segmentation | MTA    | [PDF](https://link.springer.com/article/10.1007/s11042-022-13413-x) | [Code](https://github.com/miriambellver/refvos) |

## 2021

| Model        | Title                                                        | Venue | Paper                                                        | Code                                             |
| ------------ | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ | ------------------------------------------------ |
| VOSRE        | Hierarchical Interaction Network for Video Object Segmentation from Referring Expressions | BMVC  | [PDF](https://www.bmvc2021-virtualconference.com/assets/papers/0386.pdf) |                                                  |
| CSTM*        | Collaborative Spatial-Temporal Modeling for Language-Queried Video Actor Segmentation | CVPR  | [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Hui_Collaborative_Spatial-Temporal_Modeling_for_Language-Queried_Video_Actor_Segmentation_CVPR_2021_paper.pdf) |                                                  |
| CMSA         | Referring Segmentation in Images and Videos With Cross-Modal Self-Attention Network | TPAMI | [PDF](https://ieeexplore.ieee.org/abstract/document/9336241) |                                                  |
| CMPC         | Cross-Modal Progressive Comprehension for Referring Segmentation | TPAMI | [PDF](https://ieeexplore.ieee.org/abstract/document/9430750) | [Code](https://github.com/spyflying/CMPC-Refseg) |
| ClawCraneNet | ClawCraneNet: Leveraging Object-level Relation for Text-based Video Segmentation | Arxiv | [PDF](https://arxiv.org/abs/2103.10702)                      |                                                  |
| CVLS         | Contrastive Video-Language Segmentation                      | Arxiv | [PDF](https://arxiv.org/pdf/2109.14131.pdf)                  |                                                  |



## 2020

| Model | Title                                                        | Venue | Paper                                                        | Code                                                |
| :---- | :----------------------------------------------------------- | :---- | :----------------------------------------------------------- | :-------------------------------------------------- |
| URVOS | URVOS: Unified Referring Video Object Segmentation Network with a Large-Scale Benchmark | ECCV  | [PDF](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600205.pdf) | [Code](https://github.com/skynbe/Refer-Youtube-VOS) |

## 2019

| Model | Title                                                        | Venue | Paper                                                        | Code |
| ----- | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ | ---- |
| ACGA  | Asymmetric Cross-Guided Attention Network for Actor and Action Video Segmentation From Natural Language Query | ICCV  | [PDF](https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Asymmetric_Cross-Guided_Attention_Network_for_Actor_and_Action_Video_Segmentation_ICCV_2019_paper.pdf) |      |

## 2018

| Model   | Title                                                        | Venue | Paper                                                        | Code |
| :------ | :----------------------------------------------------------- | :---- | :----------------------------------------------------------- | :--- |
| A2D*    | Actor and Action Video Segmentation from a Sentence          | CVPR  | [PDF](https://openaccess.thecvf.com/content_cvpr_2018/papers/Gavrilyuk_Actor_and_Action_CVPR_2018_paper.pdf) |      |
| VOSLRE* | Video Object Segmentation with Language Referring Expressions | ACCV  | [PDF](https://arxiv.org/pdf/1803.08006.pdf)                  |      |

